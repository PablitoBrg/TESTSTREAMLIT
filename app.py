import streamlit as st #interface
import pandas as pd
import requests
from bs4 import BeautifulSoup #Traitement des donn√©es
import re #Expression r√©guli√®re de recherche
import folium
from streamlit_folium import folium_static
import time
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
from folium.plugins import HeatMap
import plotly.graph_objects as go

# Configuration de la page
st.set_page_config(
    page_title="Coworking",
    page_icon="üè¢",
    layout="wide"
)
# Afficher les informations sur l'application
st.sidebar.image("https://mycowork.fr/wp-content/uploads/2018/03/Logo-commun-horizontal-1200-600.png")




st.markdown("""
        <style>
            [data-testid="stSidebar"] {
                background-color: #fff3f3;
                color: black;
                border-right: 2px solid #eee;
            }
        </style>
        """, unsafe_allow_html=True)
# Titre et description
st.title("üè¢Coworking Parisien")
st.markdown("""
Cette application affiche les espaces de coworking situ√©s √† Paris.
Les donn√©es sont extraites du site [leportagesalarial.com](https://www.leportagesalarial.com/coworking/).
""")


# Fonction pour extraire le code postal d'une adresse
def extract_postal_code(address):
    if not address:
        return None

    # Recherche d'un code postal fran√ßais (5 chiffres) avec un REGEX
    match = re.search(r'\b(75|91|92|93|94|77|78)\d{3}\b', address)
    if match:
        return match.group(0)[:2]  # Retourne les 2 premiers chiffres
    return None


# Fonction pour g√©ocoder une adresse
@st.cache_data
def geocode_address(address):
    if not address:
        return None, None

    geolocator = Nominatim(user_agent="coworking_app")
    try:
        location = geolocator.geocode(address, timeout=10)
        if location:
            return location.latitude, location.longitude
        return None, None
    except (GeocoderTimedOut, GeocoderServiceError):
        return None, None


# Fonction pour scraper les donn√©es
# Utilisation du d√©corateur @st.cache_data pour sauvegarder les r√©sultats de la fonction
@st.cache_data
def scrape_coworking_data():
    st.info("Extraction des donn√©es en cours... Cela peut prendre quelques minutes.")
    # On cr√©e l'ensemble de nos tableaux pour stocker les √©l√©ments scrap√©s.
    all_urls = []
    all_coworking_data = []
    # R√©cup√©ration de l'url
    website_response = requests.get("https://www.leportagesalarial.com/coworking/")
    if website_response.status_code == 200:
        html_content = website_response.text
        soup = BeautifulSoup(html_content, 'html.parser')

        # Trouver la balise <h3> qui contient le texte sp√©cifique
        h3_element = soup.find('h3', string=lambda text: text and "Coworking Paris ‚Äì √éle de France :" in text)

        # Si l'√©l√©ment h3 est trouv√©, chercher le <ul> suivant
        if h3_element:
            target_ul = h3_element.find_next('ul')

            # Extraire les URLs des √©l√©ments <li> dans target_ul
            if target_ul:
                for list_item in target_ul.find_all('li'):
                    link_element = list_item.find('a')
                    if link_element and link_element.get('href'):
                        all_urls.append(link_element.get('href'))

    # Visiter chaque URL et extraire les donn√©es
    for url in all_urls:
        page_response = requests.get(url)

        if page_response.status_code == 200:
            coworking_data = {}  # Dictionnaire pour les donn√©es de l'URL actuelle

            page_content = page_response.text
            soup = BeautifulSoup(page_content, 'html.parser')

            # Extraire le nom de l'espace de coworking
            h2_element = soup.find('h2', string=lambda text: text and "Contacter" in text)
            if h2_element:
                coworking_space_name = h2_element.text.replace("Contacter", "").strip()
                coworking_data['nom'] = coworking_space_name

                # Trouver le <ul> qui suit le h2
                contact_ul = h2_element.find_next('ul')

                if contact_ul:
                    for list_item in contact_ul.find_all('li'):
                        text = list_item.text
                        link_element = list_item.find('a')

                        # Extraire et stocker les donn√©es en fonction des mots-cl√©s
                        if "Adresse :" in text:
                            coworking_data['adresse'] = text.replace("Adresse :", "").strip()
                        elif "T√©l√©phone :" in text:
                            coworking_data['t√©l√©phone'] = text.replace("T√©l√©phone :", "").strip()
                        elif "Acc√®s :" in text:
                            coworking_data['acces'] = text.replace("Acc√®s :", "").strip()
                        elif "Site :" in text and link_element:
                            coworking_data['site'] = link_element.get('href')
                        elif "Mail :" in text and link_element:
                            coworking_data['mail'] = link_element.get('href')

            # Ajouter l'URL √† l'objet de donn√©es
            coworking_data['url'] = url

            # Ajouter le dictionnaire √† la liste seulement s'il contient des donn√©es
            if coworking_data and 'nom' in coworking_data:
                all_coworking_data.append(coworking_data)

            # Pause pour √©viter de surcharger le serveur
            time.sleep(0.5)

    return all_coworking_data


# Fonction principale
def main():
    # Bouton pour d√©clencher le scraping
    if st.button("Extraire les donn√©es des espaces de coworking"):
        coworking_data = scrape_coworking_data()

        # Convertir en DataFrame
        df = pd.DataFrame(coworking_data)

        # V√©rifier si des donn√©es ont √©t√© trouv√©es
        if df.empty:
            st.warning("Aucun espace de coworking trouv√©. Veuillez v√©rifier la structure du site web.")
            return

        # Ajouter une colonne pour le code postal
        df['code_postal'] = df['adresse'].apply(extract_postal_code)

        # Filtrer les espaces en √éle-de-France
        idf_codes = ['75', '91', '92', '93', '94', '77', '78']
        df_idf = df[df['code_postal'].isin(idf_codes)]

        if df_idf.empty:
            st.warning("Aucun espace de coworking trouv√© en √éle-de-France.")
            return

        # Afficher le nombre d'espaces trouv√©s
        st.success(f"{len(df_idf)} espaces de coworking trouv√©s en √éle-de-France.")

        # Ajouter les coordonn√©es g√©ographiques
        coordinates = []
        for address in df_idf['adresse']:
            lat, lon = geocode_address(address)
            coordinates.append((lat, lon))

        df_idf['latitude'], df_idf['longitude'] = zip(*coordinates)

        # Supprimer les lignes sans coordonn√©es valides
        df_idf = df_idf.dropna(subset=['latitude', 'longitude'])
        # Champ texte
        search_term = st.sidebar.text_input("Recherche")

        # Bouton
        if st.sidebar.button("Lancer la recherche"):
            filtered_df = df_idf[df_idf.apply(lambda row: search_term.lower() in str(row['nom']).lower()
                                                  or search_term.lower() in str(row['code_postal']).lower()
                                                  or search_term.lower() in str(row['ville']).lower(), axis=1)]
        else:
            filtered_df = df_idf
        # Afficher les donn√©es
        st.subheader("Liste des espaces de coworking")
        st.dataframe(df_idf[['nom', 'adresse', 't√©l√©phone', 'site', 'code_postal']])

        # Cr√©er la carte
        st.subheader("Carte des espaces de coworking")

        m = folium.Map(location=[48.8566, 2.3522], zoom_start=11, tiles='CartoDB dark_matter')  # Centr√© sur Paris

        # Ajouter les marqueurs
        for idx, row in df_idf.iterrows():
            if pd.notna(row['latitude']) and pd.notna(row['longitude']):
                popup_text = f"""
                <b>{row['nom']}</b><br>
                Adresse: {row['adresse']}<br>
                """

                if 't√©l√©phone' in row and pd.notna(row['t√©l√©phone']):
                    popup_text += f"T√©l√©phone: {row['t√©l√©phone']}<br>"

                if 'site' in row and pd.notna(row['site']):
                    popup_text += f"<a href='{row['site']}' target='_blank'>Site web</a><br>"

                if 'url' in row:
                    popup_text += f"<a href='{row['url']}' target='_blank'>Plus d'infos</a>"

                folium.Marker(
                    location=[row['latitude'], row['longitude']],
                    popup=folium.Popup(popup_text, max_width=300),
                    tooltip=row['nom'],
                    icon=folium.Icon(color='blue', icon='building', prefix='fa')
                ).add_to(m)

        # Afficher la carte
        left, center, right = st.columns([1, 4, 1])
        with center:
            folium_static(m)

        st.subheader("Carte thermique des espaces de coworking")

        heatmap = folium.Map(location=[48.8566, 2.3522], zoom_start=11, tiles='CartoDB dark_matter')
        HeatMap(data=df_idf[['latitude', 'longitude']].dropna().values.tolist()).add_to(heatmap)
        left, center, right = st.columns([1, 4, 1])
        with center:
            folium_static(heatmap)

        st.subheader("üìä Analyse des Espaces")

        # Cr√©ation de la colonne 'zone'
        df_idf['zone'] = df_idf['code_postal'].apply(lambda x: "Paris (75)" if x == '75' else "Campagne")

        # Comptage des occurrences
        zone_counts = df_idf['zone'].value_counts()

        # Pr√©paration des donn√©es pour Plotly
        labels = zone_counts.index.tolist()
        values = zone_counts.values.tolist()
        colors = ['#ff2c2c', '#878787']

        # Cr√©ation du camembert Plotly
        fig = go.Figure(data=[go.Pie(
            title="R√©partition des coworkings Paris / Campagne",
            labels=labels,
            values=values,
            marker=dict(colors=colors),
            textinfo='percent+label',
            hole=0,  # camembert plein, pas de donut
        )])

        # Fond transparent
        fig.update_layout(
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',  # transparent
            paper_bgcolor='rgba(0,0,0,0)',  # transparent
        )

        df_idf['has_website'] = df_idf['site'].notnull()

        # Comptage
        counts = df_idf['has_website'].value_counts()
        labels = ['Avec site web', 'Sans site web']
        values = [counts.get(True, 0), counts.get(False, 0)]

        # Couleurs personnalis√©es
        colors = ['#00BFC2', '#FF8C42']

        # Cr√©ation du graphique
        fig2 = go.Figure(data=[go.Pie(
            labels=labels,
            values=values,
            hole=0.3,
            marker=dict(colors=colors),
            textinfo='percent+label',
            hoverinfo='label+percent+value'
        )])

        # Apparence propre
        fig2.update_layout(
            title="R√©partition des coworkings avec/sans site web",
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='black')
        )

        # Cr√©er deux colonnes, on place le graphique dans la premi√®re (la moiti√© gauche)
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(fig, use_container_width=True)

        #
        with col2:
            st.plotly_chart(fig2, use_container_width=False)


# Ex√©cuter l'application
if __name__ == "__main__":
    main()



